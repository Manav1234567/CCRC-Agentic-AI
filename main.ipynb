{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c7a35a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/lib/python3.12/site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/lib/python3.12/site-packages (1.1.3)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-1.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.12/site-packages (1.1.2)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-1.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.12/site-packages (1.1.2)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/lib/python3.12/site-packages (0.4.1)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/lib/python3.12/site-packages (0.4.1)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (2.12.5)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (2.12.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-openai) (2.11.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (2.1)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-openai) (2.11.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (2.1)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_core-1.2.0-py3-none-any.whl (475 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_core-1.2.0-py3-none-any.whl (475 kB)\n",
      "Downloading langchain_openai-1.1.3-py3-none-any.whl (84 kB)\n",
      "Downloading langchain_openai-1.1.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: langchain-core, langchain-openai\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.1.3\n",
      "    Uninstalling langchain-core-1.1.3:\n",
      "      Successfully uninstalled langchain-core-1.1.3\n",
      "Installing collected packages: langchain-core, langchain-openai\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.1.3\n",
      "    Uninstalling langchain-core-1.1.3:\n",
      "      Successfully uninstalled langchain-core-1.1.3\n",
      "  Attempting uninstall: langchain-openai\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 1.1.2\n",
      "    Uninstalling langchain-openai-1.1.2:\n",
      "      Successfully uninstalled langchain-openai-1.1.2\n",
      "    Found existing installation: langchain-openai 1.1.2\n",
      "    Uninstalling langchain-openai-1.1.2:\n",
      "      Successfully uninstalled langchain-openai-1.1.2\n",
      "Successfully installed langchain-core-1.2.0 langchain-openai-1.1.3\n",
      "Successfully installed langchain-core-1.2.0 langchain-openai-1.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1. Force upgrade the critical libraries\n",
    "%pip install -U langchain langchain-core langchain-openai langchain-community pydantic\n",
    "\n",
    "# 2. IMPORTANT: You must restart the kernel after running this!\n",
    "# In VS Code/Jupyter: Click \"Restart\" or \"Restart Kernel\" in the top toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "20d1243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.2.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: shellingham in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: typer-slim in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.2.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: shellingham in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: typer-slim in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Collecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.14.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.1.7)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.14.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.1.7)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 1.2.3\n",
      "    Uninstalling huggingface_hub-1.2.3:\n",
      "      Successfully uninstalled huggingface_hub-1.2.3\n",
      "    Found existing installation: huggingface_hub 1.2.3\n",
      "    Uninstalling huggingface_hub-1.2.3:\n",
      "      Successfully uninstalled huggingface_hub-1.2.3\n",
      "Successfully installed huggingface-hub-0.36.0 safetensors-0.7.0 sentence-transformers-5.2.0 tokenizers-0.22.1 transformers-4.57.3\n",
      "Successfully installed huggingface-hub-0.36.0 safetensors-0.7.0 sentence-transformers-5.2.0 tokenizers-0.22.1 transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41c835fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ReAct Agent built successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_classic.agents import AgentExecutor, create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# Connected to LLM running locally\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://127.0.0.1:1234/v1\",\n",
    "    api_key=\"lm-studio\",\n",
    "    model=\"local-model\",\n",
    "    temperature=0,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# Define the Tool\n",
    "@tool\n",
    "def fetch_csv_dataset(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Downloads a CSV dataset from a URL and returns a summary.\n",
    "    Input should be the full URL string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse CSV\n",
    "        content = response.content.decode('utf-8')\n",
    "        df = pd.read_csv(StringIO(content), on_bad_lines='skip')\n",
    "        \n",
    "        return (\n",
    "            f\"SUCCESS: Downloaded data from {url}\\n\"\n",
    "            f\"Shape: {df.shape}\\n\"\n",
    "            f\"Columns: {list(df.columns)}\\n\"\n",
    "            f\"First 5 rows:\\n{df.head().to_string()}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "tools = [fetch_csv_dataset]\n",
    "\n",
    "# Define the ReAct Prompt (Hardcoded for stability)\n",
    "# This teaches the model explicitly how to think and act.\n",
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 4. Create the ReAct Agent\n",
    "# This uses simple text generation, avoiding the Pydantic/Tool Binding error completely.\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# 5. Create the Executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, \n",
    "    tools=tools, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True # IMPORTANT for local models\n",
    ")\n",
    "\n",
    "print(\"✅ ReAct Agent built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8a0a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: fetch_csv_dataset\n",
      "Action Input: \"https://raw.githubusercontent.com/gramener/datasets/refs/heads/main/card_transactions.csv\"\u001b[0m\u001b[32;1m\u001b[1;3mAction: fetch_csv_dataset\n",
      "Action Input: \"https://raw.githubusercontent.com/gramener/datasets/refs/heads/main/card_transactions.csv\"\u001b[0m\u001b[36;1m\u001b[1;3mSUCCESS: Downloaded data from https://raw.githubusercontent.com/gramener/datasets/refs/heads/main/card_transactions.csv\n",
      "Shape: (10000, 21)\n",
      "Columns: ['ID', 'Transaction Time', 'Transaction Type', 'Channel', 'Is 3DS', 'Is Token', 'Decision', 'Decline Reason Code', 'Issuer Name', 'Issuer Country', 'Issuer Region', 'Funding source', 'Acquirer Name', 'Acquirer Country', 'Acquirer Region', 'Jurisdiction', 'Is Dispute', 'Is Fraud', 'Dispute Type', 'Amount', 'Industry Segment']\n",
      "First 5 rows:\n",
      "                ID          Transaction Time Transaction Type Channel Is 3DS Is Token  Decision Decline Reason Code                             Issuer Name            Issuer Country Issuer Region Funding source               Acquirer Name          Acquirer Country Acquirer Region  Jurisdiction  Is Dispute  Is Fraud Dispute Type      Amount     Industry Segment\n",
      "0  T89784025544295  2024-02-20T11:02:49.000Z             Chip      CP     No       No  Approved            Approved                                    BPCE                    FRANCE        EUROPE        Credit           BOURSORAMA BANQUE                     FRANCE          EUROPE      Domestic           0         0   No Dispute  196.975798  Government services\n",
      "1  T94028747687247  2024-02-18T10:42:19.000Z        Other CNP     CNP     No       No  Approved            Approved  BANK OF AMERICA, NATIONAL ASSOCIATION   UNITED STATES OF AMERICA           USA        Credit   NAVY FEDERAL CREDIT UNION   UNITED STATES OF AMERICA             USA       Domstic           0         0   No Dispute  340.852463  Contracted services\n",
      "2  T84800389951860  2024-04-30T11:10:17.000Z            ECI-7     CNP     No       No  Approved            Approved                       HSBC UK BANK PLC             UNITED KINGDOM        EUROPE        Credit        BARCLAYS BANK UK PLC             UNITED KINGDOM          EUROPE      Domestic           0         0   No Dispute  192.134049      Clothing stores\n",
      "3  T88418230200974  2024-01-08T19:01:35.000Z      Contactless      CP     No      Yes  Approved            Approved                JPMORGAN CHASE BANK N.A   UNITED STATES OF AMERICA           USA        Credit        CHAINA MERCHANTS BANK           CHAINA MAINLAND            APAC  Cross Border           0         0   No Dispute  100.581589  Contracted services\n",
      "4  T19060182064275  2024-05-14T21:03:51.000Z             Chip      CP     No       No  Approved            Approved                    BANCO BRADESCO S.A.                     BRAZIL           LAC        Credit                 SUTTON BANK   UNITED STATES OF AMERICA             USA  Cross Border           0         0   No Dispute  424.332753     Utility services\u001b[0m\u001b[36;1m\u001b[1;3mSUCCESS: Downloaded data from https://raw.githubusercontent.com/gramener/datasets/refs/heads/main/card_transactions.csv\n",
      "Shape: (10000, 21)\n",
      "Columns: ['ID', 'Transaction Time', 'Transaction Type', 'Channel', 'Is 3DS', 'Is Token', 'Decision', 'Decline Reason Code', 'Issuer Name', 'Issuer Country', 'Issuer Region', 'Funding source', 'Acquirer Name', 'Acquirer Country', 'Acquirer Region', 'Jurisdiction', 'Is Dispute', 'Is Fraud', 'Dispute Type', 'Amount', 'Industry Segment']\n",
      "First 5 rows:\n",
      "                ID          Transaction Time Transaction Type Channel Is 3DS Is Token  Decision Decline Reason Code                             Issuer Name            Issuer Country Issuer Region Funding source               Acquirer Name          Acquirer Country Acquirer Region  Jurisdiction  Is Dispute  Is Fraud Dispute Type      Amount     Industry Segment\n",
      "0  T89784025544295  2024-02-20T11:02:49.000Z             Chip      CP     No       No  Approved            Approved                                    BPCE                    FRANCE        EUROPE        Credit           BOURSORAMA BANQUE                     FRANCE          EUROPE      Domestic           0         0   No Dispute  196.975798  Government services\n",
      "1  T94028747687247  2024-02-18T10:42:19.000Z        Other CNP     CNP     No       No  Approved            Approved  BANK OF AMERICA, NATIONAL ASSOCIATION   UNITED STATES OF AMERICA           USA        Credit   NAVY FEDERAL CREDIT UNION   UNITED STATES OF AMERICA             USA       Domstic           0         0   No Dispute  340.852463  Contracted services\n",
      "2  T84800389951860  2024-04-30T11:10:17.000Z            ECI-7     CNP     No       No  Approved            Approved                       HSBC UK BANK PLC             UNITED KINGDOM        EUROPE        Credit        BARCLAYS BANK UK PLC             UNITED KINGDOM          EUROPE      Domestic           0         0   No Dispute  192.134049      Clothing stores\n",
      "3  T88418230200974  2024-01-08T19:01:35.000Z      Contactless      CP     No      Yes  Approved            Approved                JPMORGAN CHASE BANK N.A   UNITED STATES OF AMERICA           USA        Credit        CHAINA MERCHANTS BANK           CHAINA MAINLAND            APAC  Cross Border           0         0   No Dispute  100.581589  Contracted services\n",
      "4  T19060182064275  2024-05-14T21:03:51.000Z             Chip      CP     No       No  Approved            Approved                    BANCO BRADESCO S.A.                     BRAZIL           LAC        Credit                 SUTTON BANK   UNITED STATES OF AMERICA             USA  Cross Border           0         0   No Dispute  424.332753     Utility services\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: The dataset contains the following columns:\n",
      "\n",
      "1. ID\n",
      "2. Transaction Time\n",
      "3. Transaction Type\n",
      "4. Channel\n",
      "5. Is 3DS\n",
      "6. Is Token\n",
      "7. Decision\n",
      "8. Decline Reason Code\n",
      "9. Issuer Name\n",
      "10. Issuer Country\n",
      "11. Issuer Region\n",
      "12. Funding source\n",
      "13. Acquirer Name\n",
      "14. Acquirer Country\n",
      "15. Acquirer Region\n",
      "16. Jurisdiction\n",
      "17. Is Dispute\n",
      "18. Is Fraud\n",
      "19. Dispute Type\n",
      "20. Amount\n",
      "21. Industry Segment\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "The dataset contains the following columns:\n",
      "\n",
      "1. ID\n",
      "2. Transaction Time\n",
      "3. Transaction Type\n",
      "4. Channel\n",
      "5. Is 3DS\n",
      "6. Is Token\n",
      "7. Decision\n",
      "8. Decline Reason Code\n",
      "9. Issuer Name\n",
      "10. Issuer Country\n",
      "11. Issuer Region\n",
      "12. Funding source\n",
      "13. Acquirer Name\n",
      "14. Acquirer Country\n",
      "15. Acquirer Region\n",
      "16. Jurisdiction\n",
      "17. Is Dispute\n",
      "18. Is Fraud\n",
      "19. Dispute Type\n",
      "20. Amount\n",
      "21. Industry Segment\n",
      "\u001b[32;1m\u001b[1;3mFinal Answer: The dataset contains the following columns:\n",
      "\n",
      "1. ID\n",
      "2. Transaction Time\n",
      "3. Transaction Type\n",
      "4. Channel\n",
      "5. Is 3DS\n",
      "6. Is Token\n",
      "7. Decision\n",
      "8. Decline Reason Code\n",
      "9. Issuer Name\n",
      "10. Issuer Country\n",
      "11. Issuer Region\n",
      "12. Funding source\n",
      "13. Acquirer Name\n",
      "14. Acquirer Country\n",
      "15. Acquirer Region\n",
      "16. Jurisdiction\n",
      "17. Is Dispute\n",
      "18. Is Fraud\n",
      "19. Dispute Type\n",
      "20. Amount\n",
      "21. Industry Segment\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "The dataset contains the following columns:\n",
      "\n",
      "1. ID\n",
      "2. Transaction Time\n",
      "3. Transaction Type\n",
      "4. Channel\n",
      "5. Is 3DS\n",
      "6. Is Token\n",
      "7. Decision\n",
      "8. Decline Reason Code\n",
      "9. Issuer Name\n",
      "10. Issuer Country\n",
      "11. Issuer Region\n",
      "12. Funding source\n",
      "13. Acquirer Name\n",
      "14. Acquirer Country\n",
      "15. Acquirer Region\n",
      "16. Jurisdiction\n",
      "17. Is Dispute\n",
      "18. Is Fraud\n",
      "19. Dispute Type\n",
      "20. Amount\n",
      "21. Industry Segment\n"
     ]
    }
   ],
   "source": [
    "test_url = \"https://raw.githubusercontent.com/gramener/datasets/refs/heads/main/card_transactions.csv\"\n",
    "query = f\"Download the dataset from {test_url} and tell me the columns.\"\n",
    "\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "print(\"\\n--- FINAL ANSWER ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40c1ee",
   "metadata": {},
   "source": [
    "# Vector embedding of 2022-2024 news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0848cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/207pk0bd1k932myh93lvc6jr0000gn/T/ipykernel_59110/3806328379.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors=\"coerce\", utc=True).dt.tz_convert(None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>extracted_from_tag</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>use</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>environment/2024/dec/31/country-diary-a-hogman...</td>\n",
       "      <td>Country diary: A Hogmanay fire to see in the n...</td>\n",
       "      <td>It’s a few hundred metres from where the crab ...</td>\n",
       "      <td>['environment/series/country-diary', 'environm...</td>\n",
       "      <td>environment/forests</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>True</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us-news/2024/dec/31/arbor-day-foundation-trees...</td>\n",
       "      <td>10m trees to be planted in US to replace ones ...</td>\n",
       "      <td>Some costs of the recently ended supercharged ...</td>\n",
       "      <td>['us-news/us-news', 'environment/forests', 'us...</td>\n",
       "      <td>environment/forests</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>True</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>environment/commentisfree/2024/dec/31/cicada-c...</td>\n",
       "      <td>A cicada: ‘What cicadas leave behind is a kind...</td>\n",
       "      <td>Of all the languages’ words for cicada, Croati...</td>\n",
       "      <td>['environment/series/the-nature-of', 'commenti...</td>\n",
       "      <td>environment/wildlife</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>True</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>environment/2024/dec/30/im-obsessed-with-broke...</td>\n",
       "      <td>I’m obsessed with broken shells: they are mark...</td>\n",
       "      <td>I have collected hundreds and hundreds of brok...</td>\n",
       "      <td>['environment/series/why-i-m-obsessed-with', '...</td>\n",
       "      <td>environment/series/seascape-the-state-of-our-o...</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>True</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>environment/2024/dec/30/2024s-most-costly-clim...</td>\n",
       "      <td>2024’s most costly climate disasters killed 2,...</td>\n",
       "      <td>The world’s 10 most costly climate disasters o...</td>\n",
       "      <td>['environment/climate-crisis', 'world/world', ...</td>\n",
       "      <td>us-news/hurricane-helene</td>\n",
       "      <td>EXTREME_CLIMATE_IMPACTS</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>True</td>\n",
       "      <td>EXTREME_CLIMATE_IMPACTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>environment/2022/jan/03/country-diary-on-this-...</td>\n",
       "      <td>Country diary: On this hazy morning, the dista...</td>\n",
       "      <td>Ahead of me at the far end of the path, just w...</td>\n",
       "      <td>['environment/series/country-diary', 'uk/rural...</td>\n",
       "      <td>environment/forests</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>True</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>commentisfree/2022/jan/03/as-i-bum-shuffled-my...</td>\n",
       "      <td>As I bum-shuffled my way down the scree at Ava...</td>\n",
       "      <td>Nothing beats the New Zealand bush. The writer...</td>\n",
       "      <td>['commentisfree/series/my-wild-place', 'world/...</td>\n",
       "      <td>environment/forests</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>True</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>culture/2022/jan/02/villagers-fight-to-keep-bb...</td>\n",
       "      <td>Villagers fight to keep BBC Victorian Farm in ...</td>\n",
       "      <td>Of the handful of historic working farms in th...</td>\n",
       "      <td>['culture/museums', 'environment/farming', 'ed...</td>\n",
       "      <td>environment/farming</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>True</td>\n",
       "      <td>BIODIVERSITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760</th>\n",
       "      <td>us-news/2022/jan/01/colorado-wildfires-destroy...</td>\n",
       "      <td>‘We lost everything’: Colorado wildfire destro...</td>\n",
       "      <td>Just as the flakes of the season’s first winte...</td>\n",
       "      <td>['us-news/colorado', 'world/wildfires', 'us-ne...</td>\n",
       "      <td>world/wildfires</td>\n",
       "      <td>EXTREME_CLIMATE_IMPACTS</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>EXTREME_CLIMATE_IMPACTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>news/2022/jan/01/weatherwatch-when-rivers-froz...</td>\n",
       "      <td>Weatherwatch: when rivers froze over in 1795</td>\n",
       "      <td>One upside from the climate crisis is that win...</td>\n",
       "      <td>['news/series/weatherwatch', 'environment/envi...</td>\n",
       "      <td>news/series/weatherwatch</td>\n",
       "      <td>EXTREME_CLIMATE_IMPACTS</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>EXTREME_CLIMATE_IMPACTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7762 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     environment/2024/dec/31/country-diary-a-hogman...   \n",
       "1     us-news/2024/dec/31/arbor-day-foundation-trees...   \n",
       "2     environment/commentisfree/2024/dec/31/cicada-c...   \n",
       "3     environment/2024/dec/30/im-obsessed-with-broke...   \n",
       "4     environment/2024/dec/30/2024s-most-costly-clim...   \n",
       "...                                                 ...   \n",
       "7757  environment/2022/jan/03/country-diary-on-this-...   \n",
       "7758  commentisfree/2022/jan/03/as-i-bum-shuffled-my...   \n",
       "7759  culture/2022/jan/02/villagers-fight-to-keep-bb...   \n",
       "7760  us-news/2022/jan/01/colorado-wildfires-destroy...   \n",
       "7761  news/2022/jan/01/weatherwatch-when-rivers-froz...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Country diary: A Hogmanay fire to see in the n...   \n",
       "1     10m trees to be planted in US to replace ones ...   \n",
       "2     A cicada: ‘What cicadas leave behind is a kind...   \n",
       "3     I’m obsessed with broken shells: they are mark...   \n",
       "4     2024’s most costly climate disasters killed 2,...   \n",
       "...                                                 ...   \n",
       "7757  Country diary: On this hazy morning, the dista...   \n",
       "7758  As I bum-shuffled my way down the scree at Ava...   \n",
       "7759  Villagers fight to keep BBC Victorian Farm in ...   \n",
       "7760  ‘We lost everything’: Colorado wildfire destro...   \n",
       "7761       Weatherwatch: when rivers froze over in 1795   \n",
       "\n",
       "                                                   body  \\\n",
       "0     It’s a few hundred metres from where the crab ...   \n",
       "1     Some costs of the recently ended supercharged ...   \n",
       "2     Of all the languages’ words for cicada, Croati...   \n",
       "3     I have collected hundreds and hundreds of brok...   \n",
       "4     The world’s 10 most costly climate disasters o...   \n",
       "...                                                 ...   \n",
       "7757  Ahead of me at the far end of the path, just w...   \n",
       "7758  Nothing beats the New Zealand bush. The writer...   \n",
       "7759  Of the handful of historic working farms in th...   \n",
       "7760  Just as the flakes of the season’s first winte...   \n",
       "7761  One upside from the climate crisis is that win...   \n",
       "\n",
       "                                                   tags  \\\n",
       "0     ['environment/series/country-diary', 'environm...   \n",
       "1     ['us-news/us-news', 'environment/forests', 'us...   \n",
       "2     ['environment/series/the-nature-of', 'commenti...   \n",
       "3     ['environment/series/why-i-m-obsessed-with', '...   \n",
       "4     ['environment/climate-crisis', 'world/world', ...   \n",
       "...                                                 ...   \n",
       "7757  ['environment/series/country-diary', 'uk/rural...   \n",
       "7758  ['commentisfree/series/my-wild-place', 'world/...   \n",
       "7759  ['culture/museums', 'environment/farming', 'ed...   \n",
       "7760  ['us-news/colorado', 'world/wildfires', 'us-ne...   \n",
       "7761  ['news/series/weatherwatch', 'environment/envi...   \n",
       "\n",
       "                                     extracted_from_tag  \\\n",
       "0                                   environment/forests   \n",
       "1                                   environment/forests   \n",
       "2                                  environment/wildlife   \n",
       "3     environment/series/seascape-the-state-of-our-o...   \n",
       "4                              us-news/hurricane-helene   \n",
       "...                                                 ...   \n",
       "7757                                environment/forests   \n",
       "7758                                environment/forests   \n",
       "7759                                environment/farming   \n",
       "7760                                    world/wildfires   \n",
       "7761                           news/series/weatherwatch   \n",
       "\n",
       "                     category       date   use                    label  \n",
       "0                BIODIVERSITY 2024-12-31  True             BIODIVERSITY  \n",
       "1                BIODIVERSITY 2024-12-31  True             BIODIVERSITY  \n",
       "2                BIODIVERSITY 2024-12-30  True             BIODIVERSITY  \n",
       "3                BIODIVERSITY 2024-12-30  True             BIODIVERSITY  \n",
       "4     EXTREME_CLIMATE_IMPACTS 2024-12-30  True  EXTREME_CLIMATE_IMPACTS  \n",
       "...                       ...        ...   ...                      ...  \n",
       "7757             BIODIVERSITY 2022-01-03  True             BIODIVERSITY  \n",
       "7758             BIODIVERSITY 2022-01-02  True             BIODIVERSITY  \n",
       "7759             BIODIVERSITY 2022-01-02  True             BIODIVERSITY  \n",
       "7760  EXTREME_CLIMATE_IMPACTS 2022-01-01  True  EXTREME_CLIMATE_IMPACTS  \n",
       "7761  EXTREME_CLIMATE_IMPACTS 2022-01-01  True  EXTREME_CLIMATE_IMPACTS  \n",
       "\n",
       "[7762 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/guardian_climate_news_corpus.csv\")\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
    "df = df[df['date'].dt.year >= 2022].copy()\n",
    "\n",
    "df = df[df['label'] != 'UNRELATED_TO_CLIMATE'].copy()\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d94bd620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "BIODIVERSITY               2575\n",
       "EXTREME_CLIMATE_IMPACTS    1541\n",
       "ENERGY                     1536\n",
       "POLLUTION_AND_WASTE         979\n",
       "EMISSIONS                   525\n",
       "CLIMATE_ACTIVISM            284\n",
       "CLIMATE_POLICY              269\n",
       "GLOBAL_CRISIS                38\n",
       "CLIMATE_DENIAL               15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aaaa4411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            object\n",
       "title                         object\n",
       "body                          object\n",
       "tags                          object\n",
       "extracted_from_tag            object\n",
       "category                      object\n",
       "date                  datetime64[ns]\n",
       "use                             bool\n",
       "label                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ==========================================\n",
    "# PART 1: Word2Vec on Metadata (Tags, Date, Category)\n",
    "# ==========================================\n",
    "\n",
    "# A. Preprocess: Create a \"sentence\" for each row\n",
    "# We treat the date as a string token so Word2Vec learns its relationship to other words.\n",
    "def create_metadata_sentence(row):\n",
    "    # 1. Convert date to string token (e.g., \"DATE_2023-01-15\")\n",
    "    date_token = f\"DATE_{row['date'].strftime('%Y-%m-%d')}\"\n",
    "    \n",
    "    # 2. Clean category (e.g., \"CAT_Environment\")\n",
    "    cat_token = f\"CAT_{str(row['category']).replace(' ', '_')}\"\n",
    "    \n",
    "    # 3. Process tags: split by comma if it's a string\n",
    "    if isinstance(row['tags'], str):\n",
    "        tag_tokens = [t.strip().replace(' ', '_') for t in row['tags'].split(',')]\n",
    "    else:\n",
    "        tag_tokens = []\n",
    "        \n",
    "    # Combine all into one list of tokens\n",
    "    return [date_token, cat_token] + tag_tokens\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['metadata_tokens'] = df.apply(create_metadata_sentence, axis=1)\n",
    "\n",
    "# B. Train Word2Vec\n",
    "# min_count=1 ensures even unique dates/tags are embedded (crucial for small datasets)\n",
    "# vector_size=50 is standard for metadata; use 100+ for very large datasets\n",
    "w2v_model = Word2Vec(sentences=df['metadata_tokens'], vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# C. Generate the Vectors\n",
    "# We average the vectors of all tokens in the row to get a single vector per row\n",
    "def get_mean_w2v(tokens, model):\n",
    "    valid_tokens = [t for t in tokens if t in model.wv]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean([model.wv[t] for t in valid_tokens], axis=0)\n",
    "\n",
    "df['w2v_features'] = df['metadata_tokens'].apply(lambda x: get_mean_w2v(x, w2v_model))\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# PART 2: BERT on Text (Title + Body)\n",
    "# ==========================================\n",
    "\n",
    "# A. Load a pre-trained model\n",
    "# 'all-MiniLM-L6-v2' is a fast, high-quality model for semantic similarity\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# B. Combine Title and Body\n",
    "# It is usually better to embed them together so BERT understands the title in context of the body\n",
    "df['combined_text'] = \"Title: \" + df['title'].astype(str) + \" \\nBody: \" + df['body'].astype(str)\n",
    "\n",
    "# C. Encode\n",
    "# This returns a numpy array of embeddings (e.g., shape 384)\n",
    "print(\"Encoding text with BERT... this may take a moment.\")\n",
    "embeddings = bert_model.encode(df['combined_text'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Store in DataFrame\n",
    "df['bert_features'] = list(embeddings)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# PART 3: Final Output\n",
    "# ==========================================\n",
    "\n",
    "# You now have two vector columns. You can concatenate them for machine learning.\n",
    "# Example: Creating a single X matrix\n",
    "X_w2v = np.vstack(df['w2v_features'])\n",
    "X_bert = np.vstack(df['bert_features'])\n",
    "\n",
    "# Concatenate horizontally\n",
    "X_final = np.hstack([X_w2v, X_bert])\n",
    "\n",
    "print(f\"Final Feature Matrix Shape: {X_final.shape}\")\n",
    "# Result: (rows, 50 + 384) -> (rows, 434)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
