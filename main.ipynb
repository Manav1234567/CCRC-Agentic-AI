{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3c403f",
   "metadata": {},
   "source": [
    "# Pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c8be65e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scrapy in /opt/anaconda3/lib/python3.12/site-packages (2.11.1)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (23.10.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (43.0.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (1.8.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (24.2.1)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (80.9.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (25.0)\n",
      "Requirement already satisfied: tldextract in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (5.1.2)\n",
      "Requirement already satisfied: lxml>=4.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (5.2.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /opt/anaconda3/lib/python3.12/site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=36.0.0->scrapy) (1.17.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /opt/anaconda3/lib/python3.12/site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from protego>=0.1.15->scrapy) (1.17.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from service-identity>=18.1.0->scrapy) (25.4.0)\n",
      "Requirement already satisfied: pyasn1-modules in /opt/anaconda3/lib/python3.12/site-packages (from service-identity>=18.1.0->scrapy) (0.4.2)\n",
      "Requirement already satisfied: pyasn1 in /opt/anaconda3/lib/python3.12/site-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
      "Requirement already satisfied: automat>=0.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /opt/anaconda3/lib/python3.12/site-packages (from Twisted>=18.9.0->scrapy) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: incremental>=22.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Twisted>=18.9.0->scrapy) (4.15.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from tldextract->scrapy) (3.11)\n",
      "Requirement already satisfied: requests>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tldextract->scrapy) (2.32.5)\n",
      "Requirement already satisfied: requests-file>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/anaconda3/lib/python3.12/site-packages (from tldextract->scrapy) (3.20.3)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (2025.11.12)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be0f8505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: unstructured[pdf] in /opt/anaconda3/lib/python3.12/site-packages (0.18.21)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (3.4.4)\n",
      "Requirement already satisfied: filetype in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (5.2.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (3.9.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (4.12.3)\n",
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.15.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2025.11.16)\n",
      "Requirement already satisfied: langdetect in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (3.14.3)\n",
      "Requirement already satisfied: backoff in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (4.15.0)\n",
      "Requirement already satisfied: unstructured-client in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.42.6)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (5.9.0)\n",
      "Requirement already satisfied: python-oxmsg in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.0.2)\n",
      "Requirement already satisfied: html5lib in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.1)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (3.4.4)\n",
      "Requirement already satisfied: filetype in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (5.2.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (3.9.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (4.12.3)\n",
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.15.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2025.11.16)\n",
      "Requirement already satisfied: langdetect in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (3.14.3)\n",
      "Requirement already satisfied: backoff in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (4.15.0)\n",
      "Requirement already satisfied: unstructured-client in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.42.6)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (5.9.0)\n",
      "Requirement already satisfied: python-oxmsg in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (0.0.2)\n",
      "Requirement already satisfied: html5lib in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.1)\n",
      "Collecting onnx>=1.17.0 (from unstructured[pdf])\n",
      "  Downloading onnx-1.20.1-cp312-abi3-macosx_12_0_universal2.whl.metadata (8.4 kB)\n",
      "Collecting onnx>=1.17.0 (from unstructured[pdf])\n",
      "  Downloading onnx-1.20.1-cp312-abi3-macosx_12_0_universal2.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.23.2)\n",
      "Collecting pdf2image (from unstructured[pdf])\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (1.23.2)\n",
      "Collecting pdf2image (from unstructured[pdf])\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six (from unstructured[pdf])\n",
      "  Downloading pdfminer_six-20260107-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pdfminer.six (from unstructured[pdf])\n",
      "  Downloading pdfminer_six-20260107-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pikepdf (from unstructured[pdf])\n",
      "  Downloading pikepdf-10.2.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (8.3 kB)\n",
      "Collecting pikepdf (from unstructured[pdf])\n",
      "  Downloading pikepdf-10.2.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (8.3 kB)\n",
      "Collecting pi_heif (from unstructured[pdf])\n",
      "  Downloading pi_heif-1.1.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting pi_heif (from unstructured[pdf])\n",
      "  Downloading pi_heif-1.1.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pypdf in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (6.5.0)\n",
      "Collecting google-cloud-vision (from unstructured[pdf])\n",
      "  Downloading google_cloud_vision-3.11.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pypdf in /opt/anaconda3/lib/python3.12/site-packages (from unstructured[pdf]) (6.5.0)\n",
      "Collecting google-cloud-vision (from unstructured[pdf])\n",
      "  Downloading google_cloud_vision-3.11.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting effdet (from unstructured[pdf])\n",
      "Collecting effdet (from unstructured[pdf])\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting unstructured-inference>=1.1.1 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-1.1.4-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting unstructured-inference>=1.1.1 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-1.1.4-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
      "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
      "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /opt/anaconda3/lib/python3.12/site-packages (from onnx>=1.17.0->unstructured[pdf]) (5.29.5)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx>=1.17.0->unstructured[pdf])\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (15.0.1)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /opt/anaconda3/lib/python3.12/site-packages (from onnx>=1.17.0->unstructured[pdf]) (5.29.5)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx>=1.17.0->unstructured[pdf])\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (25.12.19)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (25.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (1.14.0)\n",
      "Requirement already satisfied: python-multipart in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (0.0.21)\n",
      "Requirement already satisfied: huggingface-hub in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (0.36.0)\n",
      "Requirement already satisfied: opencv-python>=4.12 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (3.9.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (2.9.1)\n",
      "Collecting timm (from unstructured-inference>=1.1.1->unstructured[pdf])\n",
      "  Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (4.57.3)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (1.12.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (2.3.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (1.16.3)\n",
      "Requirement already satisfied: pypdfium2 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (4.30.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (11.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->unstructured[pdf]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json->unstructured[pdf]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (25.12.19)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (25.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (1.14.0)\n",
      "Requirement already satisfied: python-multipart in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (0.0.21)\n",
      "Requirement already satisfied: huggingface-hub in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (0.36.0)\n",
      "Requirement already satisfied: opencv-python>=4.12 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (3.9.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (2.9.1)\n",
      "Collecting timm (from unstructured-inference>=1.1.1->unstructured[pdf])\n",
      "  Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (4.57.3)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (1.12.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (2.3.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (1.16.3)\n",
      "Requirement already satisfied: pypdfium2 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-inference>=1.1.1->unstructured[pdf]) (4.30.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (11.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->unstructured[pdf]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json->unstructured[pdf]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (from effdet->unstructured[pdf]) (0.24.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (from effdet->unstructured[pdf]) (0.24.1)\n",
      "Collecting pycocotools>=2.0.2 (from effdet->unstructured[pdf])\n",
      "Collecting pycocotools>=2.0.2 (from effdet->unstructured[pdf])\n",
      "  Downloading pycocotools-2.0.11-cp312-abi3-macosx_10_13_universal2.whl.metadata (1.3 kB)\n",
      "  Downloading pycocotools-2.0.11-cp312-abi3-macosx_10_13_universal2.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from effdet->unstructured[pdf]) (2.3.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]) (2.45.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]) (1.27.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from html5lib->unstructured[pdf]) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from html5lib->unstructured[pdf]) (0.5.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (8.3.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (2025.11.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six->unstructured[pdf]) (43.0.0)\n",
      "Collecting Deprecated (from pikepdf->unstructured[pdf])\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from effdet->unstructured[pdf]) (2.3.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]) (2.45.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]) (1.27.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from html5lib->unstructured[pdf]) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from html5lib->unstructured[pdf]) (0.5.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (8.3.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk->unstructured[pdf]) (2025.11.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six->unstructured[pdf]) (43.0.0)\n",
      "Collecting Deprecated (from pikepdf->unstructured[pdf])\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: olefile in /opt/anaconda3/lib/python3.12/site-packages (from python-oxmsg->unstructured[pdf]) (0.47)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->unstructured[pdf]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->unstructured[pdf]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->unstructured[pdf]) (2025.11.12)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (25.1.0)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (2.12.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.17.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.72.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9.1)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore>=1.0.9->unstructured-client->unstructured[pdf]) (0.16.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (4.12.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.3)\n",
      "Requirement already satisfied: olefile in /opt/anaconda3/lib/python3.12/site-packages (from python-oxmsg->unstructured[pdf]) (0.47)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->unstructured[pdf]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->unstructured[pdf]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->unstructured[pdf]) (2025.11.12)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (25.1.0)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (2.12.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.17.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.72.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9.1)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore>=1.0.9->unstructured-client->unstructured[pdf]) (0.16.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (4.12.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.3)\n",
      "Collecting numpy (from unstructured[pdf])\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (0.4.2)\n",
      "Requirement already satisfied: safetensors in /opt/anaconda3/lib/python3.12/site-packages (from timm->unstructured-inference>=1.1.1->unstructured[pdf]) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (80.9.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (2024.12.0)\n",
      "Collecting numpy (from unstructured[pdf])\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (0.4.2)\n",
      "Requirement already satisfied: safetensors in /opt/anaconda3/lib/python3.12/site-packages (from timm->unstructured-inference>=1.1.1->unstructured[pdf]) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (80.9.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch->unstructured-inference>=1.1.1->unstructured[pdf]) (2024.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime>=1.19.0->unstructured[pdf]) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.25.1->unstructured-inference>=1.1.1->unstructured[pdf]) (0.22.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->unstructured-inference>=1.1.1->unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.19.0->unstructured[pdf]) (10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->unstructured-inference>=1.1.1->unstructured[pdf]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->unstructured-inference>=1.1.1->unstructured[pdf]) (2025.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime>=1.19.0->unstructured[pdf]) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.25.1->unstructured-inference>=1.1.1->unstructured[pdf]) (0.22.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->unstructured-inference>=1.1.1->unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.19.0->unstructured[pdf]) (10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->unstructured-inference>=1.1.1->unstructured[pdf]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->unstructured-inference>=1.1.1->unstructured[pdf]) (2025.3)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.21)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.21)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf])\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.0.3)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->unstructured-inference>=1.1.1->unstructured[pdf])\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->unstructured-inference>=1.1.1->unstructured[pdf]) (3.0.3)\n",
      "Downloading onnx-1.20.1-cp312-abi3-macosx_12_0_universal2.whl (17.9 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/17.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading onnx-1.20.1-cp312-abi3-macosx_12_0_universal2.whl (17.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_inference-1.1.4-py3-none-any.whl (47 kB)\n",
      "Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_inference-1.1.4-py3-none-any.whl (47 kB)\n",
      "Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
      "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Downloading google_cloud_vision-3.11.0-py3-none-any.whl (529 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/529.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Downloading google_cloud_vision-3.11.0-py3-none-any.whl (529 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.1/529.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pdfminer_six-20260107-py3-none-any.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.1/529.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pdfminer_six-20260107-py3-none-any.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-macosx_11_0_arm64.whl (892 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-macosx_11_0_arm64.whl (892 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.3/892.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pikepdf-10.2.0-cp312-cp312-macosx_14_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.3/892.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pikepdf-10.2.0-cp312-cp312-macosx_14_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-macosx_10_13_universal2.whl (676 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-macosx_10_13_universal2.whl (676 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Downloading pycocotools-2.0.11-cp312-abi3-macosx_10_13_universal2.whl (147 kB)\n",
      "Downloading timm-1.0.24-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Downloading pycocotools-2.0.11-cp312-abi3-macosx_10_13_universal2.whl (147 kB)\n",
      "Downloading timm-1.0.24-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: unstructured.pytesseract, pi_heif, pdf2image, numpy, Deprecated, pycocotools, pikepdf, ml_dtypes, contourpy, pdfminer.six, onnx, timm, unstructured-inference, google-cloud-vision, effdet\n",
      "  Attempting uninstall: numpy\n",
      "Installing collected packages: unstructured.pytesseract, pi_heif, pdf2image, numpy, Deprecated, pycocotools, pikepdf, ml_dtypes, contourpy, pdfminer.six, onnx, timm, unstructured-inference, google-cloud-vision, effdet\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: contourpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: contourpy 1.2.0\n",
      "    Uninstalling contourpy-1.2.0:\n",
      "      Successfully uninstalled contourpy-1.2.0\n",
      "  Attempting uninstall: contourpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: contourpy 1.2.0\n",
      "    Uninstalling contourpy-1.2.0:\n",
      "      Successfully uninstalled contourpy-1.2.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.10.1 requires numexpr>=2.6.2, which is not installed.\n",
      "open-webui 0.6.43 requires pillow==12.0.0, but you have pillow 11.3.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 20.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Deprecated-1.3.1 contourpy-1.3.3 effdet-0.4.1 google-cloud-vision-3.11.0 ml_dtypes-0.5.4 numpy-2.2.6 onnx-1.20.1 pdf2image-1.17.0 pdfminer.six-20260107 pi_heif-1.1.1 pikepdf-10.2.0 pycocotools-2.0.11 timm-1.0.24 unstructured-inference-1.1.4 unstructured.pytesseract-0.3.15\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.10.1 requires numexpr>=2.6.2, which is not installed.\n",
      "open-webui 0.6.43 requires pillow==12.0.0, but you have pillow 11.3.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 20.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Deprecated-1.3.1 contourpy-1.3.3 effdet-0.4.1 google-cloud-vision-3.11.0 ml_dtypes-0.5.4 numpy-2.2.6 onnx-1.20.1 pdf2image-1.17.0 pdfminer.six-20260107 pi_heif-1.1.1 pikepdf-10.2.0 pycocotools-2.0.11 timm-1.0.24 unstructured-inference-1.1.4 unstructured.pytesseract-0.3.15\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85e00500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain_unstructured in /opt/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.5 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_unstructured) (1.2.5)\n",
      "Requirement already satisfied: unstructured-client<1,>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_unstructured) (0.42.6)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.12.0)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (25.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (43.0.0)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (0.28.1)\n",
      "Requirement already satisfied: pypdf>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (6.5.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain_unstructured) (1.17.1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpcore>=1.0.9->unstructured-client<1,>=0.27.0->langchain_unstructured) (2025.11.12)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore>=1.0.9->unstructured-client<1,>=0.27.0->langchain_unstructured) (0.16.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain_unstructured) (4.12.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain_unstructured) (3.11)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (3.11.5)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.4.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain_unstructured) (2.21)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.3.0)\n",
      "Requirement already satisfied: langchain_unstructured in /opt/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.5 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_unstructured) (1.2.5)\n",
      "Requirement already satisfied: unstructured-client<1,>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_unstructured) (0.42.6)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.12.0)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (25.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (43.0.0)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (0.28.1)\n",
      "Requirement already satisfied: pypdf>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (6.5.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from unstructured-client<1,>=0.27.0->langchain_unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain_unstructured) (1.17.1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpcore>=1.0.9->unstructured-client<1,>=0.27.0->langchain_unstructured) (2025.11.12)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore>=1.0.9->unstructured-client<1,>=0.27.0->langchain_unstructured) (0.16.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain_unstructured) (4.12.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain_unstructured) (3.11)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (3.11.5)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (0.4.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain_unstructured) (2.21)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.5->langchain_unstructured) (2.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d88473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (5.28.2)\n",
      "Requirement already satisfied: langchain-neo4j in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-neo4j) (1.0.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-neo4j) (1.2.6)\n",
      "Requirement already satisfied: neo4j-graphrag<2.0.0,>=1.9.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-neo4j) (1.11.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (0.5.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (6.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (2.32.5)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (2.0.45)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-neo4j) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-neo4j) (25.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-neo4j) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-neo4j) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-neo4j) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-neo4j) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (4.12.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (0.16.0)\n",
      "Collecting fsspec<2025.0.0,>=2024.9.0 (from neo4j-graphrag<2.0.0,>=1.9.0->langchain-neo4j)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: json-repair<0.45.0,>=0.44.1 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from neo4j-graphrag<2.0.0,>=1.9.0->langchain-neo4j) (0.44.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=2.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from neo4j-graphrag<2.0.0,>=1.9.0->langchain-neo4j) (2.4.0)\n",
      "Requirement already satisfied: pypdf<7.0.0,>=6.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from neo4j-graphrag<2.0.0,>=1.9.0->langchain-neo4j) (6.5.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.13.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from neo4j-graphrag<2.0.0,>=1.9.0->langchain-neo4j) (1.16.3)\n",
      "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from neo4j-graphrag<2.0.0,>=1.9.0->langchain-neo4j) (6.0.12.20250915)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->langchain-classic<2.0.0,>=1.0.0->langchain-neo4j) (2.6.2)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Installing collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.10.0\n",
      "    Uninstalling fsspec-2025.10.0:\n",
      "      Successfully uninstalled fsspec-2025.10.0\n",
      "Successfully installed fsspec-2024.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neo4j langchain-neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a35a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (1.2.5)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-1.2.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (1.1.6)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (2.12.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core) (0.5.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-openai) (2.14.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-community) (2.0.45)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.13.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-community) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/climate_env/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_core-1.2.6-py3-none-any.whl (489 kB)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.13.2-cp312-cp312-macosx_11_0_arm64.whl (491 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.7.0-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl (94 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.8.0-cp312-cp312-macosx_11_0_arm64.whl (50 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl (47 kB)\n",
      "Installing collected packages: propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, dataclasses-json, aiohttp, langchain-core, langchain-community\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 1.2.5\n",
      "\u001b[2K    Uninstalling langchain-core-1.2.5:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-1.2.5\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 dataclasses-json-0.6.7 frozenlist-1.8.0 httpx-sse-0.4.3 langchain-community-0.4.1 langchain-core-1.2.6 marshmallow-3.26.2 multidict-6.7.0 mypy-extensions-1.1.0 propcache-0.4.1 typing-inspect-0.9.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langchain-core langchain-openai langchain-community pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall gensim numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U sentence-transformers transformers flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall -y bottleneck numexpr\n",
    "%pip install --upgrade pandas pyarrow numpy>=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58760a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy<2.0\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting numpy<2.0\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mUsing cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.10.1 requires numexpr>=2.6.2, which is not installed.\n",
      "open-webui 0.6.43 requires pillow==12.0.0, but you have pillow 11.3.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "neo4j-graphrag 1.11.0 requires numpy<3.0.0,>=2.0.0; python_version >= \"3.9\" and python_version < \"3.13\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 whic\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.10.1 requires numexpr>=2.6.2, which is not installed.\n",
      "open-webui 0.6.43 requires pillow==12.0.0, but you have pillow 11.3.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "neo4j-graphrag 1.11.0 requires numpy<3.0.0,>=2.0.0; python_version >= \"3.9\" and python_version < \"3.13\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 20.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mh is incompatible.\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 20.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~yarrow (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-milvus langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastapi uvicorn nest-asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d445c4",
   "metadata": {},
   "source": [
    "# Graph Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6688bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"neo4j://127.0.0.1:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"manav@1234\"\n",
    "\n",
    "EMBED_URL = \"http://127.0.0.1:8001/v1/embeddings\"\n",
    "MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
    "VECTOR_DIMENSION = 1024 \n",
    "\n",
    "LLM_URL = \"http://127.0.0.1:8000/v1/chat/completions\"\n",
    "CHAT_MODEL = \"mistralai/Ministral-3-14B-Reasoning-2512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "74b375e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT doc_hash IF NOT EXISTS FOR (e:Document) REQUIRE (e.hash) IS UNIQUE` has no effect.} {description: `CONSTRAINT doc_hash FOR (e:Document) REQUIRE (e.hash) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT doc_hash IF NOT EXISTS FOR (d:Document) REQUIRE d.hash IS UNIQUE'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT doc_path IF NOT EXISTS FOR (e:Document) REQUIRE (e.path) IS UNIQUE` has no effect.} {description: `CONSTRAINT doc_path FOR (e:Document) REQUIRE (e.path) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT doc_path IF NOT EXISTS FOR (d:Document) REQUIRE d.path IS UNIQUE'\n",
      "INFO: Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:Chunk) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:Chunk) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (c:Chunk) REQUIRE c.id IS UNIQUE'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All Constraints (Hash, Path, Chunk) initialized.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "import requests\n",
    "\n",
    "class Neo4jManager:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def check_connection(self):\n",
    "        try:\n",
    "            with self.driver.session() as session:\n",
    "                result = session.run(\"RETURN 'Connection Successful' AS msg\")\n",
    "                return result.single()[\"msg\"]\n",
    "        except Exception as e:\n",
    "            return f\"Connection Failed: {e}\"\n",
    "\n",
    "    def setup_constraints(self):\n",
    "        \"\"\"Initializes all unique constraints for the Graph.\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Content Hash: The ultimate ID for a document's content\n",
    "            session.run(\"CREATE CONSTRAINT doc_hash IF NOT EXISTS FOR (d:Document) REQUIRE d.hash IS UNIQUE\")\n",
    "            # File Path: Prevents the same path being indexed twice\n",
    "            session.run(\"CREATE CONSTRAINT doc_path IF NOT EXISTS FOR (d:Document) REQUIRE d.path IS UNIQUE\")\n",
    "            # Chunk ID: Unique identifier for text segments\n",
    "            session.run(\"CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (c:Chunk) REQUIRE c.id IS UNIQUE\")\n",
    "            print(\"✅ All Constraints (Hash, Path, Chunk) initialized.\")\n",
    "        \n",
    "    def get_processed_hashes(self):\n",
    "        \"\"\"Returns a set of all content hashes already in the DB.\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"MATCH (d:Document) RETURN d.hash AS hash\")\n",
    "            return {record[\"hash\"] for record in result}\n",
    "        \n",
    "    def is_hash_present(self, file_hash):\n",
    "        \"\"\"\n",
    "        Fast Boolean check if a Document with this hash exists.\n",
    "        Used to prevent re-embedding the same file from different sources.\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # We match strictly on the hash property\n",
    "            query = \"MATCH (d:Document {hash: $h}) RETURN count(d) > 0 as exists\"\n",
    "            result = session.run(query, h=file_hash).single()\n",
    "            return result[\"exists\"] if result else False\n",
    "        \n",
    "    def clear_data(self):\n",
    "        \"\"\"\n",
    "        Deletes all nodes and relationships. \n",
    "        Note: This keeps your constraints and indexes intact.\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # DETACH DELETE removes the node AND any relationships connected to it\n",
    "            result = session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            summary = result.consume()\n",
    "            print(f\"🧹 Data Cleared: Deleted {summary.counters.nodes_deleted} nodes \"\n",
    "                  f\"and {summary.counters.relationships_deleted} relationships.\")\n",
    "\n",
    "    def clear_schema(self):\n",
    "        \"\"\"\n",
    "        Removes all constraints and indexes from the database.\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # 1. Get all constraints\n",
    "            constraints = session.run(\"SHOW CONSTRAINTS\")\n",
    "            for record in constraints:\n",
    "                session.run(f\"DROP CONSTRAINT {record['name']}\")\n",
    "            \n",
    "            # 2. Get all indexes\n",
    "            indexes = session.run(\"SHOW INDEXES\")\n",
    "            for record in indexes:\n",
    "                # We skip lookup indexes which are system-managed\n",
    "                if record['type'] != 'LOOKUP':\n",
    "                    session.run(f\"DROP INDEX {record['name']}\")\n",
    "                    \n",
    "            print(\"🧱 Schema Cleared: All constraints and indexes removed.\")\n",
    "\n",
    "    def get_all_embedded_urls(self):\n",
    "        \"\"\"\n",
    "        Returns a list of all URLs currently stored as WebPage nodes.\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"MATCH (p:WebPage) RETURN p.url AS url ORDER BY p.url\")\n",
    "            urls = [record[\"url\"] for record in result]\n",
    "            print(f\"📋 Found {len(urls)} embedded web pages.\")\n",
    "            return urls\n",
    "\n",
    "    def delete_domain_data(self, domain):\n",
    "        \"\"\"\n",
    "        Deletes ALL WebPage nodes and their Chunks for a specific domain.\n",
    "        Example: domain=\"docs.python.org\" removes all pages from that site.\n",
    "        \"\"\"\n",
    "        print(f\"🔥 Deleting all data for domain: {domain}...\")\n",
    "        with self.driver.session() as session:\n",
    "            # We match by the 'domain' property we will store on the WebPage node\n",
    "            query = \"\"\"\n",
    "            MATCH (p:WebPage {domain: $domain})\n",
    "            OPTIONAL MATCH (p)-[:HAS_CHUNK]->(c:Chunk)\n",
    "            DETACH DELETE p, c\n",
    "            \"\"\"\n",
    "            result = session.run(query, domain=domain)\n",
    "            summary = result.consume()\n",
    "            print(f\"   🗑️ Deleted {summary.counters.nodes_deleted} nodes (Pages + Chunks).\")\n",
    "\n",
    "    def hard_reset(self):\n",
    "        \"\"\"Wipes both data and schema for a completely fresh start.\"\"\"\n",
    "        self.clear_data()\n",
    "        self.clear_schema()\n",
    "        print(\"☢️  Hard Reset Complete: The database is now empty and has no rules.\")\n",
    "\n",
    "    def get_all_publishers(self):\n",
    "        \"\"\"\n",
    "        Returns a sorted list of all unique Publishers in the Knowledge Graph.\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Match all Publisher nodes and return their 'name' property\n",
    "            query = \"\"\"\n",
    "            MATCH (p:Publisher) \n",
    "            RETURN p.name AS name \n",
    "            ORDER BY name ASC\n",
    "            \"\"\"\n",
    "            result = session.run(query)\n",
    "            \n",
    "            # Extract names from the result records\n",
    "            publishers = [record[\"name\"] for record in result]\n",
    "            \n",
    "            print(f\"📚 Found {len(publishers)} unique publishers.\")\n",
    "            return publishers\n",
    "\n",
    "    def build_graph_relationships(self):\n",
    "        \"\"\"\n",
    "        Runs post-processing to link Documents to shared Entities (Authors, Publishers, Years).\n",
    "        This creates the 'Knowledge Graph' structure where paths form between papers.\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            print(\"🔗 Starting Graph Linking Phase...\")\n",
    "\n",
    "            # 1. Unify Authors (Merge \"Smith\" from Paper A and \"Smith\" from Paper B)\n",
    "            # Result: (Author)-[:WROTE]->(Document)\n",
    "            print(\"   ...Unifying Author Nodes\")\n",
    "            session.run(\"\"\"\n",
    "            MATCH (d:Document) WHERE d.author_list IS NOT NULL\n",
    "            UNWIND d.author_list AS name\n",
    "            WITH d, trim(name) AS cleaned_name\n",
    "            WHERE size(cleaned_name) > 1  // Skip empty/garbage names\n",
    "            MERGE (a:Author {name: cleaned_name})\n",
    "            MERGE (a)-[:WROTE]->(d)\n",
    "            \"\"\")\n",
    "\n",
    "            # 2. Unify Publishers (Merge \"CSIRO\" from multiple reports)\n",
    "            # Result: (Publisher)-[:PUBLISHED]->(Document)\n",
    "            print(\"   ...Unifying Publisher Nodes\")\n",
    "            session.run(\"\"\"\n",
    "            MATCH (d:Document) WHERE d.publisher_list IS NOT NULL\n",
    "            UNWIND d.publisher_list AS pub_name\n",
    "            WITH d, trim(pub_name) AS cleaned_pub\n",
    "            WHERE size(cleaned_pub) > 1\n",
    "            MERGE (p:Publisher {name: cleaned_pub})\n",
    "            MERGE (p)-[:PUBLISHED]->(d)\n",
    "            \"\"\")\n",
    "\n",
    "            # 3. Time Hierarchy (Connect Documents to common Year Nodes)\n",
    "            # Result: (Document)-[:PUBLISHED_IN]->(Year)\n",
    "            # This allows queries like: \"Match all papers connected to Year 2024\"\n",
    "            print(\"   ...Building Time Hierarchy\")\n",
    "            session.run(\"\"\"\n",
    "            MATCH (d:Document) \n",
    "            WHERE d.year IS NOT NULL AND d.year <> 0\n",
    "            \n",
    "            // FIX: Force year to be an Integer to ensure \"2024\" connects to 2024\n",
    "            WITH d, toInteger(d.year) as year_val\n",
    "            \n",
    "            MERGE (y:Year {val: year_val})\n",
    "            MERGE (d)-[:PUBLISHED_IN]->(y)\n",
    "            \"\"\")\n",
    "\n",
    "        print(\"🚀 Graph connections complete.\")\n",
    "        \n",
    "db_manager = Neo4jManager(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "db_manager.setup_constraints()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c668a7",
   "metadata": {},
   "source": [
    "# PDF Ingestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "877fca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def extract_metadata_from_chunks(raw_docs):\n",
    "    \"\"\"\n",
    "    Uses a local LLM to extract semantic metadata from the document header.\n",
    "    Scans the first 25 elements to handle long author lists and deep metadata.\n",
    "    Returns: title, authors (humans), publishers (orgs/journals), year, full_date\n",
    "    \"\"\"\n",
    "    if not raw_docs:\n",
    "        return \"Unknown Title\", [], [], 0, None\n",
    "\n",
    "    # 1. Prepare Context \n",
    "    # We join the text but keep it under ~5000 characters to fit in the context window\n",
    "    combined_text = \"\\n\".join([c.page_content for c in raw_docs[:25]])\n",
    "    context_text = combined_text[:5000] \n",
    "\n",
    "    # 2. Strict JSON Prompt with UPDATED RULES\n",
    "    system_prompt = \"\"\"\n",
    "    You are a Strict Metadata Normalization API. Your job is to extract and STANDARDIZE key details from document headers.\n",
    "    \n",
    "    OUTPUT RULES:\n",
    "    1. Return VALID JSON only. Do not use markdown blocks (no ```json).\n",
    "    2. JSON Structure:\n",
    "       {\n",
    "         \"title\": \"String\",\n",
    "         \"authors\": [\"String\"], \n",
    "         \"publishers\": [\"String\"],\n",
    "         \"year\": Integer,\n",
    "         \"full_date\": \"String\"\n",
    "       }\n",
    "    \n",
    "    FIELD DEFINITIONS:\n",
    "    - \"authors\": List of HUMAN names who wrote THIS specific paper. \n",
    "         * Exclude organizations (move to publishers).\n",
    "         * Exclude authors mentioned in citations (e.g., ignore \"Smith (2020) argues...\").\n",
    "         - Format: \"First Initial. Last Name\" (e.g., \"T. Lane\", \"A. King\").\n",
    "         - Remove titles like \"Dr.\", \"Prof.\", \"PhD\".\n",
    "         - If a full list is not available, take the first 3 et al.\n",
    "         * If no humans are listed, return [].\n",
    "    - \"publishers\": List of all Government Agencies, or Journal Names who wrote/published THIS specific paper.\n",
    "         * Exclude author's home institution (e.g. \"\\na School of Geography, Earth and Atmospheric Sciences, The University of Melbourne, Australia\\n)\n",
    "         * Exclude \"Australian Government\" and focus on getting the department name(s), i.e., just \"Bureau of Meteorology\".\n",
    "         * Example: [\"Bureau of Meteorology\", \"ELSEVIER\", \"CSIRO\"].\n",
    "         - **Canonicalization is MANDATORY.** Convert variations to their most common form:\n",
    "            * \"Commonwealth Scientific and Industrial Research Organisation\" -> \"CSIRO\"\n",
    "            * \"CSIRO Publishing\" -> \"CSIRO\"\n",
    "            * \"Australian Government Bureau of Meteorology\" -> \"Bureau of Meteorology\"\n",
    "            * \"The Bureau of Meteorology\" -> \"Bureau of Meteorology\"\n",
    "            * \"Dept of Climate Change...\" -> \"Department of Climate Change\"\n",
    "            * \"Department of the Environment...\" -> \"Department of Environment\"\n",
    "         - Remove \"Australian Government\" prefix.\n",
    "         * Return [] if none found\n",
    "    - \"year\": The primary year associated with the document.\n",
    "         * RULE 1 (Reporting Period): If the title implies a specific reporting cycle (e.g., \"Annual Report 2022\", \"State of the Climate 2022\"), use that year, even if published in 2023.\n",
    "         * RULE 2 (Publication Date): For research papers or historical analyses (e.g., \"Climate in 1900\"), ALWAYS use the actual publication year (e.g., 2025), not the year discussed in the title.\n",
    "         * Return 0 if not found.\n",
    "    - \"full_date\": \"DD Month YYYY\" (prioritize 'Published' or 'Available online' dates). Return 0 if not found.\n",
    "\n",
    "    3. NOISE CONTROL:\n",
    "       - Do not include \"The\", \"Inc\", \"Ltd\" at the start/end of publisher names.\n",
    "       - Do not include addresses or locations (e.g. \"Melbourne, Australia\").\n",
    "    \n",
    "    4. IMPORTANT: Output minified JSON (single line).\n",
    "    \"\"\"\n",
    "\n",
    "    user_message = f\"EXTRACT METADATA FROM THIS TEXT:\\n\\n{context_text}\"\n",
    "\n",
    "    # 3. Call LLM\n",
    "    payload = {\n",
    "        \"model\": CHAT_MODEL, \n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        \"temperature\": 0.1, \n",
    "        \"stream\": False,\n",
    "        \"max_tokens\": 1500 \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(f\"{LLM_URL}\", json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        content = response.json()['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        # 4. Clean & Parse JSON\n",
    "        start_idx = content.find('{')\n",
    "        end_idx = content.rfind('}') + 1\n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            content = content[start_idx:end_idx]\n",
    "\n",
    "        data = json.loads(content)\n",
    "        \n",
    "        # Extract fields\n",
    "        title = data.get(\"title\", \"Unknown Title\")\n",
    "        authors = data.get(\"authors\", [])\n",
    "        publishers = data.get(\"publishers\", [])  # New Field\n",
    "        year = data.get(\"year\", 0)\n",
    "        full_date = data.get(\"full_date\", None)\n",
    "        \n",
    "        # Validation: Year fallback\n",
    "        if year == 0 and full_date:\n",
    "            year_match = re.search(r\"\\b(19|20)\\d{2}\\b\", full_date)\n",
    "            if year_match:\n",
    "                year = int(year_match.group(1))\n",
    "\n",
    "        return title, authors, publishers, year, full_date\n",
    "\n",
    "    except json.JSONDecodeError as je:\n",
    "        print(f\"⚠️ JSON Parsing Failed. Raw output:\\n{content}\")\n",
    "        return \"Metadata Parse Error\", [], [], 0, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Metadata Extraction Failed: {e}\")\n",
    "        # Fallback\n",
    "        fallback_title = \"Unknown Title\"\n",
    "        if raw_docs and hasattr(raw_docs[0], 'metadata') and raw_docs[0].metadata.get('category') == 'Title':\n",
    "            fallback_title = raw_docs[0].page_content\n",
    "        return fallback_title, [], [], 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "79a2cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_neo4j(db_manager, file_info, chunks, vectors, doc_vector):\n",
    "    \"\"\"\n",
    "    Writes Document and Chunks to Neo4j.\n",
    "    Updated for Trust Level and Source.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Clean Metadata\n",
    "    title = file_info.get('title', 'Unknown Title')\n",
    "    year = file_info.get('year', 0)\n",
    "    authors = file_info.get('authors', [])\n",
    "    publishers = file_info.get('publishers', [])\n",
    "    full_date = file_info.get('full_date', None)\n",
    "    file_hash = file_info['hash']\n",
    "    \n",
    "    # --- NEW FIELDS ---\n",
    "    trust_level = file_info.get('trust_level', 2) # Default to 2\n",
    "    source = file_info.get('source', 'unknown')\n",
    "\n",
    "    # 2. Cypher Query\n",
    "    query = \"\"\"\n",
    "    MERGE (d:Document {hash: $hash})\n",
    "    SET d.title = $title,\n",
    "        d.year = $year,\n",
    "        d.full_date = $full_date,\n",
    "        \n",
    "        // REPLACED category WITH trust_level AND source\n",
    "        d.trust_level = $trust_level,\n",
    "        d.source = $source,\n",
    "        \n",
    "        d.author_list = $authors,\n",
    "        d.publisher_list = $publishers,\n",
    "        d.embedding = $doc_vec\n",
    "\n",
    "    // 🛑 SAFETY: Delete old chunks\n",
    "    WITH d\n",
    "    OPTIONAL MATCH (d)-[:HAS_CHUNK]->(old_c)\n",
    "    DETACH DELETE old_c\n",
    "\n",
    "    // Create new chunks\n",
    "    WITH d\n",
    "    UNWIND $chunk_data AS chunk\n",
    "    CREATE (c:Chunk {id: chunk.id})\n",
    "    SET c.text = chunk.text, \n",
    "        c.embedding = chunk.vector, \n",
    "        c.page = chunk.page\n",
    "    \n",
    "    CREATE (d)-[:HAS_CHUNK]->(c)\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. Prepare Chunk Data\n",
    "    chunk_data = []\n",
    "    for doc, vec in zip(chunks, vectors):\n",
    "        chunk_data.append({\n",
    "            \"id\": str(uuid.uuid4()), \n",
    "            \"text\": doc.page_content, \n",
    "            \"vector\": vec, \n",
    "            \"page\": doc.metadata.get(\"page\", 1)\n",
    "        })\n",
    "\n",
    "    # 4. Execute\n",
    "    with db_manager.driver.session() as session:\n",
    "        session.run(query, \n",
    "            hash=file_hash,\n",
    "            title=title,\n",
    "            year=year,\n",
    "            full_date=full_date,\n",
    "            \n",
    "            # PASS NEW ARGS\n",
    "            trust_level=trust_level,\n",
    "            source=source,\n",
    "            \n",
    "            authors=authors,\n",
    "            publishers=publishers,\n",
    "            doc_vec=doc_vector, \n",
    "            chunk_data=chunk_data,\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ Stored '{title}' (Trust: {trust_level}, Source: {source})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c8194536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import io\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "\n",
    "# External Libs\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class SmartIngestor:\n",
    "    def __init__(self, db_manager, embed_url, model_name, base_dir=\"./data\"):\n",
    "        self.db_manager = db_manager\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.EMBED_URL = embed_url\n",
    "        self.MODEL_NAME = model_name\n",
    "\n",
    "        self.TRUSTED_DOMAINS = ['.gov.au', '.csiro.au', '.edu.au', 'nature.com', 'ipcc.ch']\n",
    "        self.TRUSTED_PUBLISHERS = [\n",
    "            'Bureau of Meteorology', 'CSIRO'\n",
    "        ]\n",
    "\n",
    "    # ENTRY POINTS \n",
    "\n",
    "    def ingest_local_file(self, file_path):\n",
    "        \"\"\"Entry point for a single local file.\"\"\"\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            file_bytes = f.read()\n",
    "        \n",
    "        file_hash = self.compute_hash_from_bytes(file_bytes)\n",
    "        filename = os.path.basename(file_path)\n",
    "\n",
    "        if self.db_manager.is_hash_present(file_hash):\n",
    "            print(f\"⏩ SKIP: '{filename}' (Already in DB)\")\n",
    "            return False\n",
    "\n",
    "        file_info = {\n",
    "            \"path\": str(file_path),\n",
    "            \"filename\": filename,\n",
    "            \"hash\": file_hash,\n",
    "            \"source\": \"local\",      # Hardcoded for files\n",
    "            \"source_url\": \"local\",  # Marker for trust check\n",
    "            \"source_type\": \"local\"\n",
    "        }\n",
    "        \n",
    "        return self._process_single_document(file_info, file_bytes=None)\n",
    "\n",
    "    def ingest_from_stream(self, filename, file_bytes, source_url):\n",
    "        \"\"\"Entry point for Web Streams.\"\"\"\n",
    "        file_hash = self.compute_hash_from_bytes(file_bytes)\n",
    "        \n",
    "        if self.db_manager.is_hash_present(file_hash):\n",
    "            print(f\"⏩ SKIP: '{filename}' (Already in DB)\")\n",
    "            return False\n",
    "\n",
    "        # Extract domain for the 'source' field (e.g., 'bom.gov.au')\n",
    "        try:\n",
    "            domain = urlparse(source_url).netloc.replace(\"www.\", \"\")\n",
    "        except:\n",
    "            domain = \"unknown_web_source\"\n",
    "\n",
    "        print(f\"🚀 INGESTING WEB PDF: '{filename}' from {domain}\")\n",
    "        \n",
    "        file_info = {\n",
    "            \"path\": None,\n",
    "            \"filename\": filename,\n",
    "            \"hash\": file_hash,\n",
    "            \"source\": domain,       # The Domain Name\n",
    "            \"source_url\": source_url,\n",
    "            \"source_type\": \"web\"\n",
    "        }\n",
    "\n",
    "        return self._process_single_document(file_info, file_bytes=file_bytes)\n",
    "\n",
    "    # CORE PROCESSING \n",
    "\n",
    "    def _determine_trust_level(self, source_url, publisher_list):\n",
    "        \"\"\"\n",
    "        Calculates Trust Score (1 = Highest, 2 = Standard).\n",
    "        Logic: Match Domain OR Match Publisher Name.\n",
    "        \"\"\"\n",
    "        # Check URL Domain\n",
    "        if source_url and source_url != \"local\":\n",
    "            if any(d in source_url.lower() for d in self.TRUSTED_DOMAINS):\n",
    "                return 1 # High Trust\n",
    "        \n",
    "        # Check Publishers\n",
    "        pub_str = \" \".join(publisher_list).lower()\n",
    "        if any(p.lower() in pub_str for p in self.TRUSTED_PUBLISHERS):\n",
    "            return 1 # High Trust\n",
    "\n",
    "        return 2 # Low Trust\n",
    "\n",
    "    def _process_single_document(self, file_info, file_bytes=None):\n",
    "        print(f\"   🔍 Analyzing Layout: {file_info['filename']}...\")\n",
    "        \n",
    "        try:\n",
    "            # LOAD\n",
    "            if file_info['source_type'] == 'local':\n",
    "                loader = UnstructuredLoader(\n",
    "                    file_path=file_info['path'],\n",
    "                    strategy=\"hi_res\",\n",
    "                    mode=\"elements\",\n",
    "                    chunking_strategy=\"by_title\",\n",
    "                    max_characters=1000,\n",
    "                    combine_text_under_n_chars=200,\n",
    "                )\n",
    "                raw_elements = loader.load()\n",
    "            else:\n",
    "                with io.BytesIO(file_bytes) as pdf_stream:\n",
    "                    loader = UnstructuredLoader(\n",
    "                        file=pdf_stream,\n",
    "                        metadata_filename=file_info['filename'],\n",
    "                        strategy=\"hi_res\",\n",
    "                        mode=\"elements\",\n",
    "                        chunking_strategy=\"by_title\",\n",
    "                        max_characters=1000,\n",
    "                        combine_text_under_n_chars=200,\n",
    "                    )\n",
    "                    raw_elements = loader.load()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ OCR/Loading Failed: {e}\")\n",
    "            return False\n",
    "\n",
    "        # EXTRACT METADATA\n",
    "        meta_tuple = extract_metadata_from_chunks(raw_elements) \n",
    "        print(f\"   Found Metadata: {meta_tuple}\")\n",
    "        \n",
    "        title, authors, publishers, year, full_date = meta_tuple\n",
    "        \n",
    "        # CALCULATE TRUST\n",
    "        trust_level = self._determine_trust_level(file_info['source_url'], publishers)\n",
    "        \n",
    "        file_info.update({\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"publishers\": publishers,\n",
    "            \"year\": year if year else 0000,\n",
    "            \"full_date\": full_date,\n",
    "            \"trust_level\": trust_level\n",
    "        })\n",
    "\n",
    "        # EMBED IDENTITY\n",
    "        identity_text = f\"Title: {title}. \"\n",
    "        if authors: identity_text += f\"Authored by: {', '.join(authors)}. \"\n",
    "        if publishers: identity_text += f\"Published by: {', '.join(publishers)}. \"\n",
    "        if year: identity_text += f\"Year: {year}.\"\n",
    "\n",
    "        doc_vector = self._generate_embedding(identity_text)\n",
    "        if not doc_vector: return False\n",
    "\n",
    "        # PROCESS CHUNKS\n",
    "        processed_chunks = []\n",
    "        for element in raw_elements:\n",
    "            content = element.page_content.strip()\n",
    "            if not content: continue\n",
    "            category = element.metadata.get(\"category\", \"Unknown\")\n",
    "            if category in [\"Header\", \"Footer\"]: continue\n",
    "\n",
    "            processed_chunks.append(Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"page\": element.metadata.get(\"page_number\", 1),\n",
    "                    \"type\": category,\n",
    "                    \"title\": file_info['title'],\n",
    "                    \"year\": file_info['year'],\n",
    "                    \"url\": file_info.get('source_url', '')\n",
    "                }\n",
    "            ))\n",
    "\n",
    "        # EMBED CHUNKS & STORE\n",
    "        batch_texts = [c.page_content for c in processed_chunks]\n",
    "        if batch_texts:\n",
    "            print(f\"   🧩 Embedding {len(processed_chunks)} chunks (Trust Level: {trust_level})...\")\n",
    "            chunk_vectors = self._generate_embedding_batch(batch_texts)\n",
    "            \n",
    "            if chunk_vectors:\n",
    "                # Pass updated file_info to storage\n",
    "                store_in_neo4j(self.db_manager, file_info, processed_chunks, chunk_vectors, doc_vector)\n",
    "                return True\n",
    "        else:\n",
    "            print(f\"   ⚠️ No text content found.\")\n",
    "            return False\n",
    "\n",
    "    # UTILS (Unchanged mainly, simplified process_local_queue)\n",
    "    \n",
    "    def compute_hash_from_bytes(self, file_bytes):\n",
    "        return hashlib.sha256(file_bytes).hexdigest()\n",
    "\n",
    "    def get_file_hash(self, filepath):\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            return self.compute_hash_from_bytes(f.read())\n",
    "            \n",
    "    def _generate_embedding(self, text):\n",
    "        try:\n",
    "            resp = requests.post(self.EMBED_URL, json={\"model\": self.MODEL_NAME, \"input\": text})\n",
    "            resp.raise_for_status()\n",
    "            return resp.json()[\"data\"][0][\"embedding\"]\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Embedding Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _generate_embedding_batch(self, texts):\n",
    "        try:\n",
    "            resp = requests.post(self.EMBED_URL, json={\"model\": self.MODEL_NAME, \"input\": texts})\n",
    "            resp.raise_for_status()\n",
    "            return [item[\"embedding\"] for item in resp.json()[\"data\"]]\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Batch Embedding Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_local_queue(self):\n",
    "        \"\"\"Scans local folder and ingests.\"\"\"\n",
    "        print(f\"--- 🛡️  Scanning Local Directory: {self.base_dir} ---\")\n",
    "        to_process = []\n",
    "        existing_hashes = self.db_manager.get_processed_hashes()\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.base_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(\".pdf\"):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    file_hash = self.get_file_hash(full_path)\n",
    "                    \n",
    "                    if file_hash in existing_hashes: continue\n",
    "                    to_process.append(full_path)\n",
    "        \n",
    "        print(f\"📊 Found {len(to_process)} new files.\")\n",
    "        for path in to_process:\n",
    "            self.ingest_local_file(path)\n",
    "            \n",
    "        if to_process:\n",
    "            print(\"\\n🔗 Running Graph Linker...\")\n",
    "            self.db_manager.build_graph_relationships()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "92802d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_manager.hard_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cbc917f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 🛡️  Scanning Local Directory: data ---\n",
      "📊 Found 1 new files.\n",
      "   🔍 Analyzing Layout: CENTRAL_SLOPES_CLUSTER_REPORT_1.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Reading PDF for file: data/climate_weather_reports/CENTRAL_SLOPES_CLUSTER_REPORT_1.pdf ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "   Found Metadata: (\"Central Slopes Cluster Report: Climate Change in Australia Projections for Australia's NRM Regions\", ['M. Ekström', 'D. Abbs', 'J. Bhend', 'F. Chiew', 'D. Kirono', 'C. Lucas', 'K. McInnes', 'A. Moise', 'F. Mpelasoka', 'L. Webb', 'P. Whetton'], ['CSIRO', 'Bureau of Meteorology'], 2015, '01 January 2015')\n",
      "   🧩 Embedding 224 chunks (Trust Level: 1)...\n",
      "✅ Stored 'Central Slopes Cluster Report: Climate Change in Australia Projections for Australia's NRM Regions' (Trust: 1, Source: local)\n",
      "\n",
      "🔗 Running Graph Linker...\n",
      "🔗 Starting Graph Linking Phase...\n",
      "   ...Unifying Author Nodes\n",
      "   ...Unifying Publisher Nodes\n",
      "   ...Building Time Hierarchy\n",
      "🚀 Graph connections complete.\n"
     ]
    }
   ],
   "source": [
    "ingestor = SmartIngestor(db_manager, EMBED_URL, MODEL_NAME, base_dir=\"./data\")\n",
    "ingestor.process_local_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c827282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Found 9 unique publishers.\n",
      "\n",
      "--- Publisher List ---\n",
      "- Bureau of Meteorology\n",
      "- CSIRO\n",
      "- Copernicus Publications\n",
      "- ELSEVIER\n",
      "- European Geosciences Union\n",
      "- Great Barrier Reef Marine Park Authority\n",
      "- NATURE COMMUNICATIONS\n",
      "- Nature Portfolio\n",
      "- npj | climate action\n"
     ]
    }
   ],
   "source": [
    "all_pubs = db_manager.get_all_publishers()\n",
    "\n",
    "print(\"\\n--- Publisher List ---\")\n",
    "for p in all_pubs:\n",
    "    print(f\"- {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1bacc7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Checking Vector Index...\n",
      "   Creating 'chunk_vector_index' with 1024 dimensions...\n",
      "   Waiting for index to come ONLINE.... (0%) ✅ Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def create_index():\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        print(\"⚙️ Checking Vector Index...\")\n",
    "        \n",
    "        # 1. Check if it exists\n",
    "        indexes = session.run(\"SHOW INDEXES\").data()\n",
    "        index_exists = any(i['name'] == 'chunk_vector_index' for i in indexes)\n",
    "        \n",
    "        if index_exists:\n",
    "            session.run(\"DROP INDEX chunk_vector_index\")\n",
    "            print(\"🗑️ Old index dropped.\")\n",
    "\n",
    "        # 2. Create it\n",
    "        print(f\"   Creating 'chunk_vector_index' with {VECTOR_DIMENSION} dimensions...\")\n",
    "        session.run(f\"\"\"\n",
    "        CREATE VECTOR INDEX chunk_vector_index IF NOT EXISTS\n",
    "        FOR (c:Chunk) ON (c.embedding)\n",
    "        OPTIONS {{indexConfig: {{\n",
    "         `vector.dimensions`: {VECTOR_DIMENSION},  \n",
    "         `vector.similarity_function`: 'cosine'\n",
    "        }}}}\n",
    "        \"\"\")\n",
    "        session.run(f\"\"\"\n",
    "        CREATE VECTOR INDEX document_vector_index IF NOT EXISTS\n",
    "        FOR (d:Document) ON (d.embedding)\n",
    "        OPTIONS {{indexConfig: {{\n",
    "         `vector.dimensions`: {VECTOR_DIMENSION},  \n",
    "         `vector.similarity_function`: 'cosine'\n",
    "        }}}}\n",
    "        \"\"\")\n",
    "        \n",
    "        # 3. Wait for it to come Online\n",
    "        print(\"   Waiting for index to come ONLINE...\", end=\"\")\n",
    "        while True:\n",
    "            status = session.run(\"SHOW INDEXES YIELD name, state, populationPercent WHERE name = 'chunk_vector_index' RETURN state, populationPercent\").single()\n",
    "            if status and status['state'] == \"ONLINE\":\n",
    "                print(\" ✅ Done!\")\n",
    "                break\n",
    "            elif status and status['state'] == \"FAILED\":\n",
    "                print(\" ❌ Index Creation Failed! Check Neo4j logs.\")\n",
    "                break\n",
    "            else:\n",
    "                percent = status['populationPercent'] if status else 0\n",
    "                print(f\". ({percent:.0f}%)\", end=\"\", flush=True)\n",
    "                time.sleep(1)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "create_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085dd70",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d462f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"neo4j://127.0.0.1:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"manav@1234\"\n",
    "\n",
    "EMBED_URL = \"http://127.0.0.1:8001/v1/embeddings\"\n",
    "EMBED_MODEL = \"jinaai/jina-embeddings-v3\"\n",
    "VECTOR_DIMENSION = 1024 \n",
    "\n",
    "LLM_URL = \"http://127.0.0.1:8000/v1/chat/completions\"\n",
    "LLM_MODEL = \"mistralai/Ministral-3-14B-Reasoning-2512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8d45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climate_backend import SmartURLIngestor, Neo4jManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4422042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: Clears the dataset empty\n",
    "\n",
    "# manager = Neo4jManager(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "# manager.hard_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab50f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚜 Starting Scrapy for domain: bom.gov.au\n",
      "   ♻️  Wiping old data for bom.gov.au...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 23:22:47 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: scrapybot)\n",
      "2026-02-09 23:22:47 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.13.1, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 23.10.0, Python 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ], pyOpenSSL 24.2.1 (OpenSSL 3.0.18 30 Sep 2025), cryptography 43.0.0, Platform macOS-26.1-arm64-arm-64bit\n",
      "2026-02-09 23:22:47 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2026-02-09 23:22:47 [py.warnings] WARNING: /opt/anaconda3/lib/python3.12/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2026-02-09 23:22:48 [scrapy.extensions.telnet] INFO: Telnet Password: fdd996bbcf12be49\n",
      "2026-02-09 23:22:48 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats',\n",
      " 'scrapy.extensions.spiderstate.SpiderState']\n",
      "2026-02-09 23:22:48 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'COOKIES_ENABLED': False,\n",
      " 'DEPTH_LIMIT': 5,\n",
      " 'LOG_LEVEL': 'INFO',\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
      "2026-02-09 23:22:48 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2026-02-09 23:22:48 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2026-02-09 23:22:48 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2026-02-09 23:22:48 [scrapy.core.engine] INFO: Spider opened\n",
      "2026-02-09 23:22:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2026-02-09 23:22:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INGESTING: https://www.bom.gov.au/sites/default/files/2023-01/water-information-urban-water-management-information-requirements-v1.1-2018.pdf\n",
      "   🔍 Analyzing Layout: water-information-urban-water-management-information-requirements-v1.1-2018.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 23:22:53 [pikepdf._core] INFO: pikepdf C++ to Python logger bridge initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 23:22:56 [unstructured_inference] INFO: Reading PDF for file: /var/folders/w4/207pk0bd1k932myh93lvc6jr0000gn/T/tmpu2s_ysb6/document ...\n",
      "2026-02-09 23:23:30 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m db_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m: NEO4J_URI,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: NEO4J_USER,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m: NEO4J_PASSWORD\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m crawler \u001b[38;5;241m=\u001b[39m SmartURLIngestor(db_config, EMBED_URL, EMBED_MODEL, LLM_URL, LLM_MODEL, Neo4jManager)\n\u001b[0;32m----> 9\u001b[0m crawler\u001b[38;5;241m.\u001b[39mingest_domain(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.bom.gov.au/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/data/Work/Research climate/CCRC-Agentic-AI/climate_backend.py:780\u001b[0m, in \u001b[0;36mSmartURLIngestor.ingest_domain\u001b[0;34m(self, start_url)\u001b[0m\n\u001b[1;32m    776\u001b[0m p \u001b[38;5;241m=\u001b[39m Process(target\u001b[38;5;241m=\u001b[39mrun_spider_process, args\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    777\u001b[0m     start_url, domain, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNeo4jManagerClass\n\u001b[1;32m    778\u001b[0m ))\n\u001b[1;32m    779\u001b[0m p\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 780\u001b[0m p\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Scrapy finished processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll(os\u001b[38;5;241m.\u001b[39mWNOHANG \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mwaitpid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid, flag)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Metadata Extraction Failed: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x354aa8cb0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "   Found Metadata: ('Unknown Title', [], [], 0, None)\n",
      "   ❌ Embedding Error: HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: /v1/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x365d768a0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 23:23:36 [scrapy.core.engine] INFO: Closing spider (shutdown)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INGESTING: https://www.bom.gov.au/sites/default/files/2025-11/water-information-register-of-changes-persons-and-commercially-sensitive-sites-v1-2025.pdf\n",
      "   🔍 Analyzing Layout: water-information-register-of-changes-persons-and-commercially-sensitive-sites-v1-2025.pdf...\n"
     ]
    }
   ],
   "source": [
    "db_config = {\n",
    "    \"uri\": NEO4J_URI,\n",
    "    \"user\": NEO4J_USER,\n",
    "    \"password\": NEO4J_PASSWORD\n",
    "}\n",
    "\n",
    "crawler = SmartURLIngestor(db_config, EMBED_URL, EMBED_MODEL, LLM_URL, LLM_MODEL, Neo4jManager)\n",
    "\n",
    "crawler.ingest_domain(\"https://www.bom.gov.au/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c961083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: source_type)} {position: line: 1, column: 20, offset: 19} for query: \"MATCH (d:Document {source_type: 'web'}) RETURN count(d) as c\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Total Web Pages Ingested: 81\n",
      "📄 Total Web PDFs Ingested: 0\n",
      "🌐 Domains: ['bom.gov.au']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 23:23:44 [unstructured_inference] INFO: Reading PDF for file: /var/folders/w4/207pk0bd1k932myh93lvc6jr0000gn/T/tmpxs3wrtru/document ...\n"
     ]
    }
   ],
   "source": [
    "manager = Neo4jManager(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "def print_crawl_stats(db_manager):\n",
    "    with db_manager.driver.session() as session:\n",
    "        # Count Pages\n",
    "        count = session.run(\"MATCH (p:WebPage) RETURN count(p) as c\").single()['c']\n",
    "        print(f\"📊 Total Web Pages Ingested: {count}\")\n",
    "        \n",
    "        # Count PDFs\n",
    "        pdf_count = session.run(\"MATCH (d:Document {source_type: 'web'}) RETURN count(d) as c\").single()['c']\n",
    "        print(f\"📄 Total Web PDFs Ingested: {pdf_count}\")\n",
    "\n",
    "        # List Domains\n",
    "        domains = session.run(\"MATCH (p:WebPage) RETURN DISTINCT p.domain as d\").data()\n",
    "        print(f\"🌐 Domains: {[d['d'] for d in domains]}\")\n",
    "\n",
    "# Run it\n",
    "print_crawl_stats(manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b2244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Fetching all ingested URLs...\n",
      "\n",
      "--- All Ingested URLs ---\n",
      "🔗 https://www.sws.bom.gov.au/?ref=ftr\n",
      "🔗 https://www.bom.gov.au/australia/meteye/?ref=ftr\n",
      "🔗 https://www.bom.gov.au/aviation/about-us/faq/\n",
      "🔗 https://www.bom.gov.au/aviation/contact-us/\n",
      "🔗 https://www.bom.gov.au/aviation/warnings/graphical-sigmet/\n",
      "🔗 https://www.bom.gov.au/aviation/\n",
      "🔗 https://www.bom.gov.au/ant/observations/map.shtml\n",
      "🔗 https://reg.bom.gov.au/climate/data-services/education.shtml\n",
      "🔗 https://www.bom.gov.au/water/regulations/search.php\n",
      "🔗 https://www.bom.gov.au/water/ssf/?ref=ftr\n",
      "🔗 https://www.bom.gov.au/water/dashboards/\n",
      "🔗 https://www.bom.gov.au/rss/?ref=ftr\n",
      "🔗 https://www.bom.gov.au/weather-services/?ref=ftr\n",
      "🔗 https://www.bom.gov.au/cgi-bin/climate/change/trendmaps.cgi\n",
      "🔗 https://www.bom.gov.au/aviation/?ref=ftr\n",
      "🔗 https://www.bom.gov.au/glossary?f%5B0%5D=type%3A100816\n",
      "🔗 https://www.bom.gov.au/bom-weather-app/weather-app-help-and-support?utm_source=beta.bom.gov.au%2Fresources%2Flearn-and-explore%2Ffire-weather-knowledge-centre&utm_medium=referral&utm_campaign=2025_09_08-kywkyr-2025&utm_content=link-apps_warning_notifications-fire_weather_kc\n",
      "🔗 https://www.bom.gov.au/bom-weather-app/weather-app-help-and-support?utm_source=beta.bom.gov.au%2Fresources%2Flearn-and-explore%2Fsevere-weather-knowledge-centre&utm_medium=referral&utm_campaign=2025_09_08-kywkyr-2025&utm_content=link-apps_warning_notifications-severe_thunderstorms_kc\n",
      "🔗 https://www.bom.gov.au/bom-weather-app/weather-app-help-and-support?utm_source=beta.bom.gov.au%2Fresources%2Flearn-and-explore%2Fheatwave-knowledge-centre&utm_medium=referral&utm_campaign=2025_09_08-kywkyr-2025&utm_content=link-apps_warning_notifications-heatwave_kc\n",
      "🔗 https://www.bom.gov.au/news-and-media/fire-weather-what-you-need-to-know\n",
      "🔗 https://www.bom.gov.au/ant/index.shtml\n",
      "🔗 https://www.bom.gov.au/resources/observation-network/kennaook/cape-grim-baseline-air-pollution-station\n",
      "🔗 https://www.bom.gov.au/news-and-media/heatwaves-what-you-need-to-know\n",
      "🔗 https://www.bom.gov.au/news-and-media/your-guide-to-using-long-range-forecasts\n",
      "🔗 https://www.bom.gov.au/news-and-media/floods-what-you-need-to-know\n",
      "🔗 https://www.bom.gov.au/bom-weather-app/weather-app-help-and-support\n",
      "🔗 https://www.bom.gov.au/manage-favourite-locations\n",
      "🔗 https://www.bom.gov.au/resources/water-information-requirements/providing-your-water-information\n",
      "🔗 https://www.bom.gov.au/resources/water-information-requirements/principles-and-policies-for-water-information\n",
      "🔗 https://www.bom.gov.au/resources/water-information-requirements/water-information-legislation\n",
      "🔗 https://www.bom.gov.au/resources/water-information-requirements/water-market-reforms\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/climate-knowledge-centre/climate-factors/el-nino-and-la-nina\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/climate-knowledge-centre/climate-factors/north-west-cloudbands\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/climate-knowledge-centre/climate-factors/frontal-systems\n",
      "🔗 https://www.bom.gov.au/resources/bomideas\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/specialised-forecasts-and-observations/alpine-regions-0\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/severe-weather-knowledge-centre\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/fire-weather-knowledge-centre\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/flood-knowledge-centre\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/heatwave-knowledge-centre\n",
      "🔗 https://www.bom.gov.au/resources/observation-network\n",
      "🔗 https://www.bom.gov.au/location/australia/new-south-wales\n",
      "🔗 https://www.bom.gov.au/resources/learn-and-explore/climate-knowledge-centre/using-long-range-forecasts\n",
      "🔗 https://www.bom.gov.au/freedom-of-information\n",
      "🔗 https://www.bom.gov.au/location/australia/victoria\n",
      "🔗 https://www.bom.gov.au/climate/cdo/\n",
      "🔗 https://www.bom.gov.au/location/australia/queensland\n",
      "🔗 https://www.bom.gov.au/location/australia/western-australia\n",
      "🔗 https://www.bom.gov.au/location/australia/south-australia\n",
      "🔗 https://www.bom.gov.au/location/australia/tasmania\n",
      "🔗 https://www.bom.gov.au/location/australia/australian-capital-territory\n",
      "🔗 https://www.bom.gov.au/location/australia/northern-territory\n",
      "🔗 https://www.bom.gov.au/resources/data-services\n",
      "🔗 https://www.bom.gov.au/contact\n",
      "🔗 https://www.bom.gov.au/glossary\n",
      "🔗 https://www.bom.gov.au/news-and-media\n",
      "🔗 https://www.bom.gov.au/bom-weather-app\n",
      "🔗 https://www.bom.gov.au/events\n",
      "🔗 https://www.bom.gov.au/tenders-and-payments\n",
      "🔗 https://www.bom.gov.au/coastal-location/australia\n",
      "🔗 https://www.bom.gov.au/disclaimer\n",
      "🔗 https://www.bom.gov.au/privacy\n",
      "🔗 https://www.bom.gov.au/\n",
      "🔗 https://www.bom.gov.au/accessibility\n",
      "🔗 https://www.bom.gov.au/government-and-industry/industry-sectors/aviation-sector\n",
      "🔗 https://www.bom.gov.au/sitemap\n",
      "🔗 https://www.bom.gov.au/government-and-industry/industry-sectors/transport-sector\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/specialised-forecasts-and-observations\n",
      "🔗 https://www.bom.gov.au/copyright\n",
      "🔗 https://www.bom.gov.au/government-and-industry/industry-sectors/space-sector\n",
      "🔗 https://www.bom.gov.au/government-and-industry/industry-sectors/energy-and-resources-sector\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/water-data-and-forecasts\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/specialised-forecasts-and-observations/rainfall-and-river-conditions\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/specialised-forecasts-and-observations/tropical-cyclone\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/specialised-forecasts-and-observations/tsunami\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/specialised-forecasts-and-observations/heatwave\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/long-range-weather\n",
      "🔗 https://www.bom.gov.au/government-and-industry/industry-sectors/agriculture-sector\n",
      "🔗 https://www.bom.gov.au/government-and-industry/industry-sectors\n",
      "🔗 https://www.bom.gov.au/government-and-industry\n",
      "🔗 https://www.bom.gov.au/weather-and-climate/past-weather-and-climate\n",
      "\n",
      "✅ Total URLs found: 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Metadata Extraction Failed: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x355475ca0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "   Found Metadata: ('Unknown Title', [], [], 0, None)\n",
      "   ❌ Embedding Error: HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: /v1/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x365d4f1d0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 23:26:16 [scrapy.extensions.logstats] INFO: Crawled 91 pages (at 91 pages/min), scraped 83 items (at 83 items/min)\n",
      "2026-02-09 23:26:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 47926,\n",
      " 'downloader/request_count': 126,\n",
      " 'downloader/request_method_count/GET': 126,\n",
      " 'downloader/response_bytes': 4534737,\n",
      " 'downloader/response_count': 126,\n",
      " 'downloader/response_status_count/200': 90,\n",
      " 'downloader/response_status_count/301': 34,\n",
      " 'downloader/response_status_count/401': 1,\n",
      " 'downloader/response_status_count/404': 1,\n",
      " 'dupefilter/filtered': 6645,\n",
      " 'elapsed_time_seconds': 208.322422,\n",
      " 'finish_reason': 'shutdown',\n",
      " 'finish_time': datetime.datetime(2026, 2, 9, 12, 26, 16, 432822, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 14759565,\n",
      " 'httpcompression/response_count': 90,\n",
      " 'item_scraped_count': 89,\n",
      " 'log_count/INFO': 15,\n",
      " 'log_count/WARNING': 1,\n",
      " 'memusage/max': 1696694272,\n",
      " 'memusage/startup': 624115712,\n",
      " 'request_depth_max': 5,\n",
      " 'response_received_count': 92,\n",
      " 'scheduler/dequeued': 126,\n",
      " 'scheduler/dequeued/disk': 126,\n",
      " 'scheduler/enqueued': 1069,\n",
      " 'scheduler/enqueued/disk': 1069,\n",
      " 'start_time': datetime.datetime(2026, 2, 9, 12, 22, 48, 110400, tzinfo=datetime.timezone.utc)}\n",
      "2026-02-09 23:26:16 [scrapy.core.engine] INFO: Spider closed (shutdown)\n"
     ]
    }
   ],
   "source": [
    "def list_all_ingested_urls(db_manager):\n",
    "    \"\"\"\n",
    "    Fetches and prints ALL ingested WebPage URLs from the database.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    MATCH (p:WebPage)\n",
    "    RETURN p.url as url, p.title as title\n",
    "    ORDER BY p.last_crawled DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔍 Fetching all ingested URLs...\")\n",
    "    \n",
    "    with db_manager.driver.session() as session:\n",
    "        results = session.run(query)\n",
    "        count = 0\n",
    "        \n",
    "        print(\"\\n--- All Ingested URLs ---\")\n",
    "        for record in results:\n",
    "            count += 1\n",
    "            print(f\"🔗 {record['url']}\")\n",
    "            # Optional: print title if you want\n",
    "            # print(f\"   Title: {record['title']}\") \n",
    "            \n",
    "        print(f\"\\n✅ Total URLs found: {count}\")\n",
    "\n",
    "# Usage:\n",
    "list_all_ingested_urls(manager)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
